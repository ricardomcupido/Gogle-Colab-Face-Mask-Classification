{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Modelo_ResNet152V2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"rrDfgzhXaiCs"},"source":["import itertools\n","import os\n","\n","import matplotlib.pylab as plt\n","import numpy as np\n","from numpy import interp\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","from tensorflow.python.keras.layers import Conv2D, Dense, Flatten, GlobalAveragePooling2D\n","\n","\n","from keras import backend as K\n","from keras import models \n","from keras.utils.vis_utils import plot_model\n","from keras.models import Sequential\n","\n","from itertools import cycle\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","\n","from google.colab import drive\n","\n","import pathlib"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zzZVpzWJdWJ0"},"source":["#Se monta la unidad de Google Drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","#Se almacenan los datos de la carpeta Train\n","data_train = \"/content/gdrive/MyDrive/Codigo_Colab/conjunto-datos/Train\"\n","data_train = pathlib.Path(data_train)\n","\n","#Se almacenan los datos de la carpeta Test\n","data_test = \"/content/gdrive/MyDrive/Codigo_Colab/conjunto-datos/Test\"\n","data_test = pathlib.Path(data_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bsv6O4B6cBuo"},"source":["#Se define el tamaño de entrada de las imagenes\n","IMAGE_SIZE=(224,224)\n","#Se define el tamaño del lote de datos que se utilizara \n","BATCH_SIZE=15"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R-D9sn6ZQLOs"},"source":["datagen_kwargs = dict(rescale=1./255)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uGKhHoOPoldB"},"source":["#Se utiliza la funcion ImageDataGenerator en conjunto con el diccionario para reescalar las imagenes de prueba\n","test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    **datagen_kwargs)\n","#Definimos los operadores para la modificacion de las imagenes en ImageGnerator\n","train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=20,\n","\t\tzoom_range=0.1,\n","\t\twidth_shift_range=0.2,\n","\t\theight_shift_range=0.2,\n","\t\tshear_range=0.15,\n","    horizontal_flip=True,\n","    fill_mode= \"nearest\",\n","    **datagen_kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S9zv4indTUur"},"source":["#Creamos el generador con los datos de prueba\n","test_generator = test_datagen.flow_from_directory(\n","    data_test, target_size=IMAGE_SIZE,  color_mode=\"rgb\" ,batch_size=1450,\n","     class_mode='categorical',\n","     shuffle=False)\n","#Generador con los datos de \n","train_generator = train_datagen.flow_from_directory(\n","    data_train, subset=\"training\", shuffle=True, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, color_mode=\"rgb\",\n","                   interpolation=\"bilinear\", class_mode='categorical')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9D67iVQxp0Pp"},"source":["#Extraccion de las variables X y Y del generador\n","x_test, y_test = next(test_generator)\n","x_train, y_train = next(train_generator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OvOMCv_HgFSy"},"source":["#Definicion de las metricas\n","#Sensibilidad\n","def recall_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","#Precision\n","def precision_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","#F1\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 5*((precision*recall)/(precision+recall+K.epsilon()))\n","#Especificidad\n","def specificity(y_true, y_pred):\n","    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n","    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n","    return true_negatives / (possible_negatives + K.epsilon())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M67Fe6u3tCq1"},"source":["#Creacion del modelo\n","resn_model = tf.keras.applications.ResNet152V2(input_shape=(224, 224,3), include_top=False, weights=None)\n","\n","resn_model.trainable = True\n","\n","fine_tune_at = 100\n","for layer in resn_model.layers[:fine_tune_at]:\n","    layer.trainable =  False\n","\n","model = Sequential([resn_model,\n","                    GlobalAveragePooling2D(),\n","                    Flatten(),\n","                    Dense(5, activation='softmax')])\n","\n","model.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.01), \n","  loss='categorical_crossentropy',\n","  metrics=['accuracy',specificity, precision_m, recall_m])\n","\n","model.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RIpF0fsc5QZ6"},"source":["steps_per_epoch = train_generator.samples // train_generator.batch_size\n","hist = model.fit(\n","    train_generator,\n","    epochs=10, steps_per_epoch=steps_per_epoch).history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YiNNe0F5hKMg"},"source":["#Creacion de la matriz de confusion\n","y_pred=model.predict(x_test, batch_size=BATCH_SIZE)\n","y_pred = np.argmax(y_pred, axis=1)\n","cm=confusion_matrix(test_generator.classes, y_pred)\n","print(cm)\n","#Impresion de la exactitud\n","accu = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","accu =accu.diagonal()\n","print(accu)\n","#Reporte de metricas\n","target_names = ['KN95', 'N95', 'Generico', 'Quirurgico', 'Sin_cubrebocas']\n","print(classification_report(test_generator.classes, y_pred, target_names=target_names, digits=4))\n","\n","loss, accuracy, specificity, precision, recall = model.evaluate(test_generator, verbose=0)\n","print(loss, accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_ydb51ul_v9"},"source":["#Grafica de las metricas\n","plt.figure()\n","plt.ylabel(\"Perdida\")\n","plt.xlabel(\"Pasos de entrenamiento\")\n","plt.ylim([0,0.5])\n","plt.plot(hist[\"loss\"])\n","\n","plt.figure()\n","plt.ylabel(\"Accuracy (training and test)\")\n","plt.xlabel(\"Training Steps\")\n","plt.ylim([0.5,1])\n","plt.plot(hist[\"accuracy\"])\n","\n","plt.figure()\n","plt.ylabel(\"Especificidad\")\n","plt.xlabel(\"Pasos de entrenamiento\")\n","plt.ylim([0.9,1])\n","plt.plot(hist[\"specificity\"])\n","\n","plt.figure()\n","plt.ylabel(\"Sensibilidad\")\n","plt.xlabel(\"Pasos de entrenamiento\")\n","plt.ylim([0.6,1])\n","plt.plot(hist[\"recall_m\"])\n","\n","plt.figure()\n","plt.ylabel(\"Precision\")\n","plt.xlabel(\"Pasos de entrenamiento\")\n","plt.ylim([0.6,1])\n","plt.plot(hist[\"precision_m\"])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VBsphDcUXbAx"},"source":["import matplotlib.pyplot as plt\n","\n","# Impresion de la curva ROC\n","lw = 2\n","y_score = model.predict(x_test)\n","n_classes= 5\n","# Calcular la curva ROC para cada clase\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","for i in range(n_classes):\n","    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Calculo de curva ROC Micropromedio y el area ROC\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","# Calculo la curva ROC macro-promedio y el área ROC\n","\n","# Agregar las tasas de los falsos positivos\n","all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","\n","# Luego interpole todas las curvas ROC en estos puntos\n","mean_tpr = np.zeros_like(all_fpr)\n","for i in range(n_classes):\n","    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n","\n","# Promedio y calcule el AUC\n","mean_tpr /= n_classes\n","\n","fpr[\"macro\"] = all_fpr\n","tpr[\"macro\"] = mean_tpr\n","roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","# Graficacion de las cruvas por clase\n","plt.figure(1)\n","\n","colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n","for i, color in zip(range(n_classes), colors):\n","    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n","             label='Curva ROC de la clase {0} (area = {1:0.4f})'\n","             ''.format(i, roc_auc[i]))\n","\n","#Primer grafica de curvas ROC\n","plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.ylabel('Sensibilidad')\n","plt.xlabel('1-Especificidad')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","#Zoom de la primer grafica \n","plt.figure(2)\n","plt.xlim(0, 0.08)\n","plt.ylim(0.9, 1)\n","\n","\n","colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n","for i, color in zip(range(n_classes), colors):\n","    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n","             label='Curva ROC de la clase {0} (area = {1:0.4f})'\n","             ''.format(i, roc_auc[i]))\n","\n","plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n","plt.ylabel('Sensibilidad')\n","plt.xlabel('1-especificidad')\n","\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQJFBHGDmCGr"},"source":["#Obtener aquellas imagenes mal clasificadas por el modelo\n","def get_class_string_from_index(index):\n","   for class_string, class_index in test_generator.class_indices.items():\n","      if class_index == index:\n","         return class_string\n","\n","count=0\n","while count < len(x_test):\n","  image = x_test[count,: , :, :]\n","  true_index = np.argmax(y_test[count])\n","  \n","  prediction_scores = model.predict(np.expand_dims(image, axis=0))\n","  predicted_index = np.argmax(prediction_scores)\n","  confidence= np.amax(prediction_scores)\n","  if true_index != predicted_index:\n","    plt.imshow(image)\n","    plt.axis('off')\n","    plt.show()\n","    print(\"True label: \" + get_class_string_from_index(true_index))\n","    print(\"Predicted label: \" + get_class_string_from_index(predicted_index))\n","    print(\"Confidence: \" + str(confidence))\n","  count+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B3wEVcP8iq3V"},"source":["#Almacenar el modelo\n","model.save(\"/content/gdrive/MyDrive/modelo_Res152.h5\", save_format=\"h5\")\n","converter = tf.lite.TFLiteConverter.from_keras_model(model6)\n","tflite_model = converter.convert()\n","#convertir el modelo a archivo tflite\n","with open('/content/gdrive/MyDrive/modelo_Res152.tflite', 'wb') as f:\n","  f.write(tflite_model)"],"execution_count":null,"outputs":[]}]}